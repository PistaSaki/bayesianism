{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Example \n",
    "Andel example 7.102, pg 160"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\R}{\\mathbb{R}}$\n",
    "$\\newcommand{\\P}{\\mathbb{P}}$\n",
    "$\\newcommand{\\argmax}[1]{\\underset{#1}{\\mathrm{argmax}}}$\n",
    "\n",
    "For $i \\in \\{0, \\ldots N -1\\}$ consider independent \n",
    "$$ Z^{(0)}_i,Z^{(1)}_i \\sim Norm(Y_i, \\sigma^2)$$\n",
    "We measure all $Z$, we want to estimate $\\sigma^2$ and we don't care about the values of $Y$.\n",
    "\n",
    "### Maximal likelihood estimator\n",
    "We have measured numbers $Z_i^{(k)}$ look for estimates $\\hat Y_i, \\hat\\sigma$ of unknown parameters $Y_i, \\sigma$ by maximizing the log-likelihood \n",
    "$$\\log\\P[Z \\mid Y,\\sigma] = \\sum_{i = 0}^{N-1} \\log\\P[Z_i^{(0)}, Z_i^{(1)} \\mid Y_i,\\sigma]$$\n",
    "#### Find $\\hat Y_i$\n",
    "If we fix $\\sigma$ then maximization wrt $Y$ splits into $N$ independent maximizations $\\hat Y_i(\\sigma) = \\argmax{Y_i}\\ \\log\\P[Z_i^{(0)}, Z_i^{(1)} \\mid Y_i,\\sigma]$. This is the standard max-likelihood estimation of the unknown mean $Y_i$ of a normal disribution given its scale $\\sigma$ and samples $Z_i^{(k)};\\ k \\in \\{0, 1\\}$. Thus \n",
    "$\\hat Y_i (\\sigma) = \\frac{Z_i^{(0)} + Z_i^{(1)}}{2}$. Since the right-hand side does not depend on $\\sigma$ we have in fact found\n",
    "$$\\hat Y_i= \\frac{Z_i^{(0)} + Z_i^{(1)}}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find $\\hat\\sigma$\n",
    "Now we can find $\\sigma$ by maximizing\n",
    "$$\\sum_{i = 0}^{N-1} \\sum_{k=0}^1\\log Norm\\left[Z_i^{(k)} \\ \\middle|\\ \\hat Y_i, \\sigma\\right] = 2\\sum_{i = 0}^{N-1} \\log Norm\\left[\\frac{Z_i^{(0)} - Z_i^{(1)}}{2}\\ \\middle|\\, 0, \\sigma \\right] $$ \n",
    "This is equivalent to finding max-lhd estimate of the scale parameter of a normal distribution with mean 0 and measurements $\\frac{Z_i^{(0)} - Z_i^{(1)}}{2}$. So we get\n",
    "$$\\hat\\sigma^2 = \\frac{1}{N} \\sum_i \\left(\\frac{Z_i^{(0)} - Z_i^{(1)}}{2} \\right)^2 = \\frac{1}{4} \\sum_i \\frac{\\left(Z_i^{(0)} - Z_i^{(1)}\\right)^2}{N}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inconsistency \n",
    "As $N\\to\\infty$ we get from LLN: \n",
    "$$\\hat\\sigma^2 = \\frac{1}{4} \\sum_i \\frac{\\left(Z_i^{(0)} - Z_i^{(1)}\\right)^2}{N} \\to \\frac 1 2 \\sigma^2.$$\n",
    "so it is not very satisfactory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian approach\n",
    "**Remark:** The prior does not save us by itself. If we maximized the joint posterior on $\\sigma^2, Y$, we would run into the same problem. Since it is only $\\sigma$ that is of interest, we must maximize the marginal posterior $\\P\\left(\\sigma\\mid Z\\right) = \\sum_Y\\P\\left(\\sigma, Y\\mid Z\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T16:15:09.369751Z",
     "start_time": "2018-01-09T16:15:09.057751Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as pl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T16:15:13.749751Z",
     "start_time": "2018-01-09T16:15:11.930751Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.distributions as tfd\n",
    "from tensorflow.distributions import Normal, Bernoulli\n",
    "from tensorflow.nn import softmax\n",
    "from tensorflow import exp, log, ones, zeros\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T13:10:21.902765Z",
     "start_time": "2018-01-11T13:10:21.897764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## changing the width of cells\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T16:15:13.753751Z",
     "start_time": "2018-01-09T16:15:13.750751Z"
    }
   },
   "outputs": [],
   "source": [
    "floatX = np.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian model\n",
    "God generates \"forces\" $Y_i\\sim Norm(\\mu, \\lambda^2)$ for $i\\in\\{0, \\ldots N-1\\}$.\n",
    "Afterwards, Nature generates observations $Z^{(0)}_i,Z^{(1)}_i \\sim Norm(Y_i, \\sigma^2)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate artificial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "μ_true = 0.\n",
    "λ_true = 3.\n",
    "σ_true = 2.\n",
    "N = 100\n",
    "\n",
    "Y_true = Normal(μ_true, λ_true).sample(N)\n",
    "Z_obs = Normal(Y_true, σ_true).sample(2)\n",
    "Z_obs = tf.transpose(Z_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2089aae3a90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## plot input data\n",
    "fig, ax = pl.subplots()\n",
    "ax.set_aspect(\"equal\")\n",
    "pl.scatter(*Z_obs.numpy().T)\n",
    "pl.scatter(Y_true.numpy(), Y_true.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change of variables\n",
    "We have constraints $\\lambda, \\sigma >0$. To get rid of them we introduce\n",
    "$$\\beta = \\log\\lambda^2,\\,\\gamma=\\log\\sigma^2 \\quad\\text{i.e.}\\quad \\lambda = e^{\\beta/2}, \\sigma = e^{\\gamma/2}.$$\n",
    "We take our model paramters to be $\\theta := (\\mu, \\beta, \\gamma)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_μλσ(θ):\n",
    "    μ, β, γ = θ\n",
    "    λ = exp(β/2)\n",
    "    σ = exp(γ/2)\n",
    "    return μ, λ, σ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given distributions\n",
    "$\\newcommand{P}{\\mathbb{P}}$\n",
    "$\\newcommand{R}{\\mathbb{R}}$\n",
    "$\\newcommand{Z}{\\mathbb{Z}}$\n",
    "$\\newcommand{E}{\\mathbb{E}}$\n",
    "#### $\\P(\\theta)$ - prior on model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "μ_prior = Normal(loc=0., scale=1.)\n",
    "β_prior = Normal(loc=0., scale=1.)\n",
    "γ_prior = Normal(loc=0., scale=1.)\n",
    "\n",
    "def θ_log_prior(θ) -> \"scalar\":\n",
    "    μ, β, γ = θ\n",
    "    return μ_prior.log_prob(μ) + β_prior.log_prob(β) + γ_prior.log_prob(γ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=83, shape=(), dtype=float32, numpy=-2.7568154>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test\n",
    "θ_log_prior((0., 0., 0.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\P(Y_i\\mid \\theta)$ - \"prior\" on latent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Y_log_priors(Y, θ):\n",
    "    μ, λ, σ = get_μλσ(θ)\n",
    "    return Normal(μ, λ).log_prob(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(100)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test\n",
    "Y_log_priors(Y_true, (0.,0.,0.)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\P(Z_i\\mid Y_i,\\ \\theta)$ - \"likelihood\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Z_log_probas(Z, Y, θ):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        Z: tensor of shape `[N, 2]`\n",
    "        Y: tensor of shape `[N]`\n",
    "        θ: tuple of model parameters\n",
    "    Returns:\n",
    "        tensor of shape `[N]`\n",
    "    \"\"\"\n",
    "    μ, λ, σ = get_μλσ(θ)\n",
    "    return tf.reduce_sum(\n",
    "        Normal(loc=Y[:, None], scale=σ).log_prob(Z),\n",
    "        axis = -1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(100)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test\n",
    "Z_log_probas(Z_obs, Y_true, (0.,0.,0.)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM-algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(100), Dimension(2)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_reps = 1\n",
    "Z = tf.tile(Z_obs, [n_reps, 1])\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = tf.Variable(zeros(Z.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ = (\n",
    "    tf.Variable(0., name = \"mu\"),\n",
    "    tf.Variable(0., name = \"beta\"),\n",
    "    tf.Variable(0., name = \"gamma\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "μ, β, γ = θ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E-step --- MCMC\n",
    "* Do several independent MCMC updates of all $y_i$ with the unnormalized densities $y_i\\mapsto  \\P(y_i\\mid \\theta) \\cdot \\P(z_i\\mid \\theta, y_i)$\n",
    "\n",
    "Denote `losses[i]:=` $-\\log\\P(y_i\\mid \\theta) -\\log \\P(z_i\\mid \\theta, y_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_losses(Z, Y, θ) -> \"Tensor of shape [N]\":\n",
    "    return - Y_log_priors(Y, θ) - Z_log_probas(Z, Y, θ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MetropolisHastings_update(\n",
    "    x: tf.Variable, get_losses: Callable, step_size:float, n_steps:int=1\n",
    ") -> None:\n",
    "    \"\"\"Update values in `x` using several steps of Metropolis-Hastings algorithm.\n",
    "    \n",
    "    We want to sample a batch of independent random variables $x_i$ given by batch of \n",
    "    unnormalized densities $f_i(x_i)$. These $f(i)$ are specified by\n",
    "    `get_losses(x)[i]` = $-log(f_i(x_i))$.\n",
    "    \"\"\"\n",
    "\n",
    "    loss_current = get_losses(x)\n",
    "    for i in range(n_steps):\n",
    "        x_suggest = Normal(loc=x, scale=step_size).sample()\n",
    "        loss_suggest = get_losses(x_suggest)\n",
    "\n",
    "        proba_of_step = tf.minimum(exp(loss_current - loss_suggest), 1)\n",
    "        step_or_not = Bernoulli(probs=proba_of_step, dtype = tf.bool).sample()\n",
    "\n",
    "        x.assign(tf.where(step_or_not, x_suggest, x));\n",
    "        loss_current = tf.where(step_or_not, loss_suggest, loss_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test\n",
    "def test_MetropolisHastings_update():\n",
    "    \"\"\"Use Metropolis-Hastings to sample from  Normal(0, 1).\"\"\"\n",
    "    x = tf.Variable(zeros(100))\n",
    "    MetropolisHastings_update(\n",
    "        x, get_losses = lambda x: - Normal(0., 1.).log_prob(x), \n",
    "        step_size=.1, n_steps=1000)\n",
    "    mean, var = tf.nn.moments(x, axes=0)\n",
    "    assert abs(mean) < 0.3 and abs(var - 1) < 0.3\n",
    "\n",
    "test_MetropolisHastings_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(step_size=0.1, n_steps=100) -> None: \n",
    "    MetropolisHastings_update(\n",
    "        get_losses = lambda x: get_losses(Z=Z, Y=x, θ=θ),\n",
    "        x = Y,\n",
    "        step_size = step_size,\n",
    "        n_steps = n_steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M-step --- gradient descent on $\\theta$\n",
    "\n",
    "with fixed $y$ make several gradient-descent steps in $\\theta$ as if trying to maximize the function of $\\theta$\n",
    "$$\\theta \\mapsto \\log\\big(\\P(\\theta) \\cdot\\P(y\\mid \\theta) \\cdot \\P(z\\mid \\theta, y)\\big)$$\n",
    "Denote `loss:=` $-\\log\\P(\\theta) - \\sum_i\\log\\P(y_i\\mid \\theta)  - \\sum_i\\log\\P(z_i\\mid \\theta, y_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(Z, Y, θ) -> \"scalar\":\n",
    "    return θ_log_prior(θ) - tf.reduce_sum(Y_log_priors(Y, θ)) - tf.reduce_sum(Z_log_probas(Z, Y, θ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(n_steps:int = 100) -> None:\n",
    "    for i in range(n_steps):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = get_loss(Z, Y, θ)\n",
    "\n",
    "        grad = tape.gradient(loss, θ)\n",
    "        optimizer.apply_gradients(zip(grad, θ))\n",
    "   \n",
    "M_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run EM-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    E_step(step_size=1., n_steps=10)\n",
    "    M_step(n_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'mu:0' shape=() dtype=float32, numpy=-0.36479232>,\n",
       " <tf.Tensor: id=3715217, shape=(), dtype=float32, numpy=2.7168918>,\n",
       " <tf.Tensor: id=3715220, shape=(), dtype=float32, numpy=2.1930106>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_μλσ(θ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 3.0, 2.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "μ_true, λ_true, σ_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bordel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step_only_gamma(n_steps:int = 100) -> None:\n",
    "    for i in range(n_steps):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = get_loss(Z, Y, θ)\n",
    "\n",
    "        grad = tape.gradient(loss, γ)\n",
    "        optimizer.apply_gradients([(grad, γ)])\n",
    "   \n",
    "M_step_only_gamma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=4.6051702>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "μ.assign(μ_true)\n",
    "β.assign(log(λ_true**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100000):\n",
    "    E_step(step_size=0.01, n_steps=10)\n",
    "    M_step_only_gamma(n_steps=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#400040",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#000000",
    "wrapper_background": "#ffffff"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "1072px",
    "left": "0px",
    "right": "656px",
    "top": "164px",
    "width": "144px"
   },
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
